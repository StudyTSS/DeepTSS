{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "import h5py\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.load('X0.npy')\n",
    "X_1 = np.load('X1.npy')\n",
    "\n",
    "X = np.append(X_0,  X_1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = np.ones((X_1.shape[0]))\n",
    "y_0 = np.zeros((X_0.shape[0]))\n",
    "\n",
    "y = np.append(y_0,  y_1, axis=0)\n",
    "y = y.reshape(y.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_hot = (np.arange(X.max()) == X[...,None]-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_one_hot.reshape(X_one_hot.shape[0], X_one_hot.shape[1] * X_one_hot.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = X_one_hot.reshape(X_one_hot.shape[0],  X_one_hot.shape[1], X_one_hot.shape[2],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train, Test, Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X_, y , test_size=0.15, shuffle = True)\n",
    "X_train, X_val, y_train, y_val  = train_test_split(X_train, y_train, test_size=0.15, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCC metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCC(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    '''\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONV2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Create the model : a network with 3 convolutional layers and a dense layer '''\n",
    "\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.models import Model \n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "num_classes =1\n",
    "batch_size = 2014\n",
    "num_epochs = 150\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4,4),activation='relu',input_shape=(299,4,1),padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D((1, 2),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (4, 4), activation='relu',padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(MaxPooling2D(pool_size=(1, 2),padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LeakyReLU(alpha=0.1))                  \n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='min', period=1)\n",
    "early = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
    "class_weight = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train.reshape(y_train.shape[0]))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy',MCC])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          epochs=num_epochs,\n",
    "          batch_size=batch_size,\n",
    "          validation_data=(X_val, y_val), callbacks=[checkpointer,early], class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights.hdf5')\n",
    "fashion_model.compile(loss='binary_crossentropy',\n",
    "              optimizer= 'adam', metrics=['accuracy',MCC])\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('score_CNN_TSS_Start_', score)\n",
    "np.save('h_DA_MCC_train_', np.asarray(history.history['MCC']))\n",
    "np.save('h_DA_MCC_val_', np.asarray(history.history['val_MCC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = fashion_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('y_pred_CNN_TSS_Start_', y_pred)\n",
    "np.save('y_test_CNN_TSS_Start_', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
